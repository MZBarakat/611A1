{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 2: Linear Models and Validation Metrics (30 marks total)\n",
    "### Due: October 10 at 11:59pm\n",
    "\n",
    "### Name: Moaz Barakat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 1: Classification (14.5 marks total)\n",
    "\n",
    "You have been asked to develop code that can help the user determine if the email they have received is spam or not. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3c6fc8",
   "metadata": {},
   "source": [
    "### Step 0: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33f86925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from yellowbrick.datasets import load_spam\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/spam.html\n",
    "\n",
    "Use the yellowbrick function `load_spam()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "33583c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Size:  262200 , Shape:  (4600, 57)\n",
      "y Size:  4600 , Shape:  (4600,)\n",
      "word_freq_make                float64\n",
      "word_freq_address             float64\n",
      "word_freq_all                 float64\n",
      "word_freq_3d                  float64\n",
      "word_freq_our                 float64\n",
      "word_freq_over                float64\n",
      "word_freq_remove              float64\n",
      "word_freq_internet            float64\n",
      "word_freq_order               float64\n",
      "word_freq_mail                float64\n",
      "word_freq_receive             float64\n",
      "word_freq_will                float64\n",
      "word_freq_people              float64\n",
      "word_freq_report              float64\n",
      "word_freq_addresses           float64\n",
      "word_freq_free                float64\n",
      "word_freq_business            float64\n",
      "word_freq_email               float64\n",
      "word_freq_you                 float64\n",
      "word_freq_credit              float64\n",
      "word_freq_your                float64\n",
      "word_freq_font                float64\n",
      "word_freq_000                 float64\n",
      "word_freq_money               float64\n",
      "word_freq_hp                  float64\n",
      "word_freq_hpl                 float64\n",
      "word_freq_george              float64\n",
      "word_freq_650                 float64\n",
      "word_freq_lab                 float64\n",
      "word_freq_labs                float64\n",
      "word_freq_telnet              float64\n",
      "word_freq_857                 float64\n",
      "word_freq_data                float64\n",
      "word_freq_415                 float64\n",
      "word_freq_85                  float64\n",
      "word_freq_technology          float64\n",
      "word_freq_1999                float64\n",
      "word_freq_parts               float64\n",
      "word_freq_pm                  float64\n",
      "word_freq_direct              float64\n",
      "word_freq_cs                  float64\n",
      "word_freq_meeting             float64\n",
      "word_freq_original            float64\n",
      "word_freq_project             float64\n",
      "word_freq_re                  float64\n",
      "word_freq_edu                 float64\n",
      "word_freq_table               float64\n",
      "word_freq_conference          float64\n",
      "char_freq_;                   float64\n",
      "char_freq_(                   float64\n",
      "char_freq_[                   float64\n",
      "char_freq_!                   float64\n",
      "char_freq_$                   float64\n",
      "char_freq_#                   float64\n",
      "capital_run_length_average    float64\n",
      "capital_run_length_longest      int64\n",
      "capital_run_length_total        int64\n",
      "dtype: object\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import spam dataset from yellowbrick library\n",
    "# Note: regular import did not work due to a bug with yellowbrick. I downloaded the dataset (loadspam) and used the relative path\n",
    "X, y = load_spam(data_home=\"Lab2/spambase.data\")\n",
    "# TO DO: Print size and type of X and y\n",
    "print(\"X Size: \", X.size, \", Shape: \", X.shape)\n",
    "print(\"y Size: \", y.size, \", Shape: \", y.shape)\n",
    "print(X.dtypes)\n",
    "print(y.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (1.5 marks)\n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e7204f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_freq_make                0\n",
      "word_freq_labs                0\n",
      "word_freq_857                 0\n",
      "word_freq_data                0\n",
      "word_freq_415                 0\n",
      "word_freq_85                  0\n",
      "word_freq_technology          0\n",
      "word_freq_1999                0\n",
      "word_freq_parts               0\n",
      "word_freq_pm                  0\n",
      "word_freq_direct              0\n",
      "word_freq_cs                  0\n",
      "word_freq_meeting             0\n",
      "word_freq_original            0\n",
      "word_freq_project             0\n",
      "word_freq_re                  0\n",
      "word_freq_edu                 0\n",
      "word_freq_table               0\n",
      "word_freq_conference          0\n",
      "char_freq_;                   0\n",
      "char_freq_(                   0\n",
      "char_freq_[                   0\n",
      "char_freq_!                   0\n",
      "char_freq_$                   0\n",
      "char_freq_#                   0\n",
      "capital_run_length_average    0\n",
      "capital_run_length_longest    0\n",
      "word_freq_telnet              0\n",
      "word_freq_lab                 0\n",
      "word_freq_address             0\n",
      "word_freq_650                 0\n",
      "word_freq_all                 0\n",
      "word_freq_3d                  0\n",
      "word_freq_our                 0\n",
      "word_freq_over                0\n",
      "word_freq_remove              0\n",
      "word_freq_internet            0\n",
      "word_freq_order               0\n",
      "word_freq_mail                0\n",
      "word_freq_receive             0\n",
      "word_freq_will                0\n",
      "word_freq_people              0\n",
      "word_freq_report              0\n",
      "word_freq_addresses           0\n",
      "word_freq_free                0\n",
      "word_freq_business            0\n",
      "word_freq_email               0\n",
      "word_freq_you                 0\n",
      "word_freq_credit              0\n",
      "word_freq_your                0\n",
      "word_freq_font                0\n",
      "word_freq_000                 0\n",
      "word_freq_money               0\n",
      "word_freq_hp                  0\n",
      "word_freq_hpl                 0\n",
      "word_freq_george              0\n",
      "capital_run_length_total      0\n",
      "dtype: int64\n",
      "<bound method NDFrame._add_numeric_operations.<locals>.sum of 0       False\n",
      "3057    False\n",
      "3058    False\n",
      "3059    False\n",
      "3060    False\n",
      "        ...  \n",
      "1531    False\n",
      "1530    False\n",
      "1529    False\n",
      "1535    False\n",
      "4599    False\n",
      "Name: is_spam, Length: 4600, dtype: bool>\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary\n",
    "nullsX = X.isnull().sum().sort_values(ascending=False)\n",
    "nullsy = y.isnull().sort_values().sum\n",
    "print(nullsX) #Note: no nulls confirmed\n",
    "print(nullsy) #Note: no nulls confirmed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a489285a",
   "metadata": {},
   "source": [
    "For this task, we want to test if the linear model would still work if we used less data. Use the `train_test_split` function from sklearn to create a new feature matrix named `X_small` and a new target vector named `y_small` that contain **5%** of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9bc4a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Create X_small and y_small \n",
    "X_small, X_test, y_small, y_test = train_test_split(X, y, train_size=0.05) #note test sets will be used in step 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `LogisticRegression` from sklearn\n",
    "2. Instantiate model `LogisticRegression(max_iter=2000)`.\n",
    "3. Implement the machine learning model with three different datasets: \n",
    "    - `X` and `y`\n",
    "    - Only first two columns of `X` and `y`\n",
    "    - `X_small` and `y_small`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f255549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing LogisticRegression from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Instiating the model with max_iter = 2000\n",
    "#3.1\n",
    "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(X, y, test_size=0.2)\n",
    "logreg_Xy = LogisticRegression(max_iter=2000).fit(X_train_full, y_train_full)\n",
    "\n",
    "#3.2, only first two coulumns\n",
    "x_sample = X.loc[:, [X.columns[0], X.columns[1]]]\n",
    "X_train_sample, X_test_sample, y_train_sample, y_test_sample = train_test_split(x_sample, y, test_size=0.2)\n",
    "logreg_Xysample = LogisticRegression(max_iter=2000).fit(X_train_sample, y_train_sample)\n",
    "\n",
    "#3.3\n",
    "logreg_Xysmall = LogisticRegression(max_iter=2000).fit(X_small, y_small)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89f3d84",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model\n",
    "\n",
    "Calculate the training and validation accuracy for the three different tests implemented in Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5ca55c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score for X and y\n",
      "training accuracy (all data) 0.928\n",
      "training accuracy (cross-validation) 0.930\n",
      "validation accuracy (cross-validation) 0.922\n",
      "test accuracy (new data) 0.922\n",
      "\n",
      "Score for X and y (first two columns)\n",
      "training accuracy (all data) 0.616\n",
      "training accuracy (cross-validation) 0.618\n",
      "validation accuracy (cross-validation) 0.618\n",
      "test accuracy (new data) 0.623\n",
      "\n",
      "Score for X_small and y_small\n",
      "training accuracy (all data) 0.935\n",
      "training accuracy (cross-validation) 0.946\n",
      "validation accuracy (cross-validation) 0.878\n",
      "test accuracy (new data) 0.914\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def print_accuracy_validation(name, model, X_train, y_train, X_test, y_test) : #Summarizes the different scores\n",
    "    print(\"\\nScore for\", name)\n",
    "\n",
    "    scores = cross_validate(model, X_train, y_train, cv=5, \n",
    "                        scoring='accuracy',\n",
    "                       return_train_score=True)\n",
    "    print('training accuracy (all data) {:.3f}'.format(model.score(X_train, y_train)))\n",
    "    print('training accuracy (cross-validation) {:.3f}'.format(scores['train_score'].mean()))\n",
    "    print('validation accuracy (cross-validation) {:.3f}'.format(scores['test_score'].mean()))\n",
    "    print('test accuracy (new data) {:.3f}'.format(model.score(X_test, y_test)))\n",
    "    return model.score(X_train, y_train), model.score(X_test, y_test) #Note: return values used in step 5\n",
    "\n",
    "\n",
    "ta_1, va_1 = print_accuracy_validation(\"X and y\", model=logreg_Xy, X_train=X_train_full, y_train=y_train_full, X_test=X_test_full, y_test=y_test_full)\n",
    "ta_2, va_2 = print_accuracy_validation(\"X and y (first two columns)\", model=logreg_Xysample, X_train=X_train_sample, y_train=y_train_sample, X_test=X_test_sample, y_test=y_test_sample)\n",
    "ta_3, va_3 = print_accuracy_validation(\"X_small and y_small\", model=logreg_Xysmall, X_train=X_small, y_train=y_small, X_test=X_test, y_test=y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352106a3",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Data size, training accuracy, validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be4b5c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data size</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7360.0</td>\n",
       "      <td>0.616033</td>\n",
       "      <td>0.622826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13110.0</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.913501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>209760.0</td>\n",
       "      <td>0.928261</td>\n",
       "      <td>0.921739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data size  Training Accuracy  Validation Accuracy\n",
       "1     7360.0           0.616033             0.622826\n",
       "2    13110.0           0.934783             0.913501\n",
       "0   209760.0           0.928261             0.921739"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: Steps 3-4 are above\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "#5.1\n",
    "results = pd.DataFrame(columns=[\"Data size\",\"Training Accuracy\", \"Validation Accuracy\"])\n",
    "\n",
    "#5.2, HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "for size, ta, va in zip([X_train_full.size, X_train_sample.size, X_small.size],[ta_1, ta_2, ta_3],[va_1, va_2, va_3]):\n",
    "     results.loc[len(results)] = [size,ta,va]\n",
    "\n",
    "results.sort_values(\"Data size\", inplace = True)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4427d4f",
   "metadata": {},
   "source": [
    "### Questions (4 marks)\n",
    "1. How do the training and validation accuracy change depending on the amount of data used? Explain with values.\n",
    "2. In this case, what do a false positive and a false negative represent? Which one is worse?\n",
    "\n",
    "*YOUR ANSWERS HERE*\n",
    "1. As shown in the above table, the training and validation accuracy tend to increase as the data size increase.\n",
    "This is evident for all the datasets shown in sorted order. Example 7360 produced ~0.62 validation and 209760 produced ~0.93\n",
    "2. This is a binary classification, hence we have two classes. *positive* class and *negative* class.\n",
    "\n",
    "In the spam dataset, we are trying to identify emails that are spam. \n",
    "- The *positive* class would be 'Spam'\n",
    "- The *negative* class would be 'Non-spam'.\n",
    "\n",
    "**False positive**: If we falsly label a sample as *positive* that in reality is *negative*. \n",
    "- We say that an email is a spam, whereas in reality it is not.\n",
    "\n",
    "**False negative**: If we falsly label a sample as *negative* that in reality is *positive*. \n",
    "- We miss to identify an email as spam.\n",
    "\n",
    "Typically which is one is worst depends on the application and priorities. For me, *False positives* in this case is way worse than *False negatives*. The reason being marking a regular email as spam is bad compared to the other (E.g what if it is an important email)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7559517a",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fe687f",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413e6396",
   "metadata": {},
   "source": [
    "1. Where did you source your code?\n",
    " - Code is based on a combination of lectures examples and documentation from scikit learn\n",
    "  - Lecture examples adopted from: <cite>Introduction to Machine Learning with Python, Müller and Guido, 1st ed, 2016 https://github.com/amueller/introduction_to_ml_with_python</cite>\n",
    "  - Scikit learn general documentation available at: <cite> https://scikit-learn.org/stable/ </cite>\n",
    "  - Spam dataset: <cite> https://www.scikit-yb.org/en/latest/api/datasets/spam.html </cite>\n",
    "2. In what order did you complete the steps?\n",
    "  - The order of the steps was done as per the assignment, steps 1-5 as it seemed logically\n",
    "3. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "  - Similar to assignment 1, I explicitly avoided using any generative AI throughout this process so I can learn while doing the assignment\n",
    "4. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?\n",
    "  - Yes I did have challenges. One of the challenges was to deal with the yellowbricks bug which prevented me from loading the dataset normally. I overcame this by downloading the dataset and used a relative path to load the dataset. Otherwise, everything else was straightforward and the examples on D2L really helped me a lot. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4c78a8",
   "metadata": {},
   "source": [
    "## Part 2: Regression (10.5 marks total)\n",
    "\n",
    "For this section, we will be evaluating concrete compressive strength of different concrete samples, based on age and ingredients. You will need to repeat the steps 1-4 from Part 1 for this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ba83c5",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6ff2e34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Size:  8240 , Shape:  (1030, 8)\n",
      "y Size:  1030 , Shape:  (1030,)\n",
      "cement    float64\n",
      "slag      float64\n",
      "ash       float64\n",
      "water     float64\n",
      "splast    float64\n",
      "coarse    float64\n",
      "fine      float64\n",
      "age         int64\n",
      "dtype: object\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import concrete dataset from yellowbrick library\n",
    "from yellowbrick.datasets import load_concrete\n",
    "X, y = load_concrete() #Note: concrete dataset worked, spam dataset did not work and required manually downloading\n",
    "# TO DO: Print size and type of X and y\n",
    "print(\"X Size: \", X.size, \", Shape: \", X.shape)\n",
    "print(\"y Size: \", y.size, \", Shape: \", y.shape)\n",
    "print(X.dtypes)\n",
    "print(y.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5294cfa",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (0.5 marks)\n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "693c5fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cement    0\n",
      "slag      0\n",
      "ash       0\n",
      "water     0\n",
      "splast    0\n",
      "coarse    0\n",
      "fine      0\n",
      "age       0\n",
      "dtype: int64\n",
      "<bound method NDFrame._add_numeric_operations.<locals>.sum of 0       False\n",
      "678     False\n",
      "679     False\n",
      "680     False\n",
      "681     False\n",
      "        ...  \n",
      "349     False\n",
      "350     False\n",
      "351     False\n",
      "385     False\n",
      "1029    False\n",
      "Name: strength, Length: 1030, dtype: bool>\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary\n",
    "nullsX = X.isnull().sum().sort_values(ascending=False)\n",
    "nullsy = y.isnull().sort_values().sum\n",
    "print(nullsX) #Note: no nulls confirmed\n",
    "print(nullsy) #Note: no nulls confirmed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc60489",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model (1 mark)\n",
    "\n",
    "1. Import `LinearRegression` from sklearn\n",
    "2. Instantiate model `LinearRegression()`.\n",
    "3. Implement the machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b5041945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# Importing LinearRegression from sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# 3.1, instantiate the model\n",
    "model = LinearRegression()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) #Note splitted set for train/test\n",
    "# 3.2, implement the machine learning model\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de28482",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model (1 mark)\n",
    "\n",
    "Calculate the training and validation accuracy using mean squared error and R2 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "970c038b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "Mean Squared Error: 95.635\n",
      "R2 Error: 0.637\n",
      "Root Mean Squared Error: 9.779\n",
      "Mean Absolute Error: 7.865\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "rt = r2_score(y_test, predictions)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "print(\"Linear Regression:\")\n",
    "print(f\"Mean Squared Error: {mse:.3f}\")\n",
    "print(f\"R2 Error: {rt:.3f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.3f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aa7795",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (1 mark)\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: MSE and R2 score\n",
    "2. Add the accuracy results to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "88d223f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>110.346</td>\n",
       "      <td>95.635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>0.609</td>\n",
       "      <td>0.637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Training Accuracy  Validation Accuracy\n",
       "MSE            110.346               95.635\n",
       "R2               0.609                0.637"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "#5.1\n",
    "results = pd.DataFrame(columns=[\"Training Accuracy\", \"Validation Accuracy\"], index = ['MSE', 'R2'])\n",
    "\n",
    "#5.2\n",
    "predictions_trn = model.predict(X_train)\n",
    "predictions_tst = model.predict(X_test)\n",
    "\n",
    "for pred, act, i in zip([predictions_trn,predictions_tst], [y_train, y_test], [0,1]):\n",
    "     mse_r = mean_squared_error(act, pred)\n",
    "     rt_r = r2_score(act, pred)\n",
    "     results[results.columns[i]] = [round(mse_r,3), round(rt_r,3)]\n",
    "\n",
    "#5.3\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a42bda",
   "metadata": {},
   "source": [
    "### Questions (2 marks)\n",
    "1. Did using a linear model produce good results for this dataset? Why or why not?\n",
    " - In my opinion, I think the model can be further improved. Take for example the 0.64 R2 value. This means the remaining 36 % of the variability is still unaccounted for which is not very promising. This makes sense since the compressive strength is complex and nonlinear feature in nature. Due to the low variance and high bias observed, it looks like the model is underfitting the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca0ff2f",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdb0880",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36f94da",
   "metadata": {},
   "source": [
    "1. Where did you source your code?\n",
    " - Code is based on a combination of lectures examples and documentation from scikit learn\n",
    "  - Lecture slides adopted from: <cite>Introduction to Machine Learning with Python, Müller and Guido, 1st ed, 2016 https://github.com/amueller/introduction_to_ml_with_python</cite>\n",
    "  - Scikit learn general documentation available at: <cite> https://scikit-learn.org/stable/ </cite>\n",
    "  - Concrete dataset: <cite> https://www.scikit-yb.org/en/latest/api/datasets/concrete.html </cite>\n",
    "2. In what order did you complete the steps?\n",
    "  - The order of the steps was done as per the assignment, steps 1-5 as it seemed logically\n",
    "3. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "  - Similar to assignment 1, I explicitly avoided using any generative AI throughout this process so I can learn while doing the assignment\n",
    "4. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?\n",
    "  - No major challenges, everything was straightforward and the examples on D2L really helped me a lot. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72ac3eb",
   "metadata": {},
   "source": [
    "## Part 3: Observations/Interpretation (3 marks)\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "*ADD YOUR FINDINGS HERE*\n",
    "\n",
    "General:\n",
    "The ML process for both classification and regression is very similar and follows the machine learning workflow we are taught in the lectures\n",
    "\n",
    "The ML process:\n",
    "- Data input: the load spam and load concrete\n",
    "- Data processing: detecting if there are any nulls and processing the data if required\n",
    "- Choosing a ML model: for the case of spam we used LogesticRegression and for concrete we used LinearRegression\n",
    "- Validation: for both cases we validated the model, validation I've used is cross-validation, test score, train score, R2, MSE\n",
    "- Visualization: for both cases we had a summarization table and viewed the result\n",
    " \n",
    "\n",
    "The spam dataset:\n",
    "- The model accuracy increases as the size of the dataset increases - as evident by the table in step #5 of part 1\n",
    "- In the best case we are able to verify ~93% accurately a spam email (7% misclassification)\n",
    "- The result has a decently high accuracy but the 7% misclassification is not a small issue\n",
    "- Training and validation scores (for all cases) were similar, this means we have low variance and we are not overfitting\n",
    "- As evident from the code below, the top two words to identifying a spam email is the \"your\" and \"000\"\n",
    "\n",
    "\n",
    "The concrete dataset:\n",
    "- The linear model produced a 0.64 R2 score (ideal value = 1) and 95.64 MSE (ideal value = 0)\n",
    "- The remaining 36 % of the variability is still unaccounted\n",
    "- Training and validation scores were similar (0.61 & 0.64), we have low variance \n",
    "- Validation scores are far from maximum (1), we have high bias.\n",
    "- This suggests the model underfits the data\n",
    "- As evident from the code below, the top two correlated features related to the yield strength are the cement and splast\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5b7eeff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Yield Strength', 'cement', 'splast'], dtype='object')\n",
      "Index(['Is Spam', 'word_freq_your', 'word_freq_000'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "data1 = pd.DataFrame(load_concrete()[0])\n",
    "data1[\"Yield Strength\"] = load_concrete()[1]\n",
    "cols1 = data1.corr().abs().nlargest(3, 'Yield Strength')['Yield Strength'].index\n",
    "print(cols1)\n",
    "\n",
    "data2 = pd.DataFrame(load_spam(data_home=\"Lab2/spambase.data\")[0])\n",
    "data2[\"Is Spam\"] = load_spam(data_home=\"Lab2/spambase.data\")[1]\n",
    "cols2 = data2.corr().abs().nlargest(3, 'Is Spam')['Is Spam'].index\n",
    "print(cols2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b84eed",
   "metadata": {},
   "source": [
    "## Part 4: Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "*ADD YOUR THOUGHTS HERE*\n",
    "\n",
    "what you liked or disliked: \n",
    "- I liked that we went through both examples of classification and regression \n",
    "\n",
    "found interesting, confusing, challangeing, motivating:\n",
    "- It was intersting how the ML process is similar for classification and regression. Addtionally, the example datasets were intersting and motivating\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db951b3a",
   "metadata": {},
   "source": [
    "## Part 5: Bonus Question (4 marks)\n",
    "\n",
    "Repeat Part 2 with Ridge and Lasso regression to see if you can improve the accuracy results. Which method and what value of alpha gave you the best R^2 score? Is this score \"good enough\"? Explain why or why not.\n",
    "\n",
    "**Remember**: Only test values of alpha from 0.001 to 100 along the logorithmic scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "47623d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ridge Regression: \n",
      "R2 Error: 0.63693669\n",
      "Mean Squared Error: 95.62517337\n",
      "\n",
      "Lasso Regression:\n",
      "R2 Error: 0.63689949\n",
      "Mean Squared Error: 95.63497052\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "\n",
    "#Ridge ----------------------------------------------------\n",
    "ridge_model = Ridge(alpha=100)  \n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "ridge_predictions = ridge_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "ridge_rt = r2_score(y_test, ridge_predictions)\n",
    "ridge_mse = mean_squared_error(y_test, ridge_predictions)\n",
    "\n",
    "\n",
    "print(\"\\nRidge Regression: \")\n",
    "print(f\"R2 Error: {ridge_rt:.8f}\")\n",
    "print(f\"Mean Squared Error: {ridge_mse:.8f}\")\n",
    "\n",
    "\n",
    "#Lasso ----------------------------------------------------\n",
    "lasso_model = Lasso(alpha=0.001)  \n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "lasso_predictions = lasso_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "lasso_rt = r2_score(y_test, lasso_predictions)\n",
    "lasso_mse = mean_squared_error(y_test, lasso_predictions)\n",
    "\n",
    "\n",
    "print(\"\\nLasso Regression:\")\n",
    "print(f\"R2 Error: {lasso_rt:.8f}\")\n",
    "print(f\"Mean Squared Error: {lasso_mse:.8f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b606236",
   "metadata": {},
   "source": [
    "*ANSWER HERE*\n",
    "\n",
    " Which method and what value of alpha gave you the best R^2 score?\n",
    " - Ridge with 100 as alpha gave the highest R2 score \n",
    "\n",
    " Is this score \"good enough\"? Explain why or why not\n",
    " - No, it did not improve the model significantally and it was not good enough to move away from underfitting the data. I still think linear model to this problem will not suffice, we will need a different model to achieve higher accuracy "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
